# -*- coding: utf-8 -*-
"""finetune_tp4_hardcoded.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YyVe5-UshkI-F5TZakWrYMIezHwkTCND
"""

from transformers import BertForTokenClassification, BertTokenizer, AdamW, get_linear_schedule_with_warmup

from torch.utils.data import DataLoader, TensorDataset
import torch

from torch.nn import CrossEntropyLoss

def convert_IOB2_to_BERT_data(filepath):
    training_data = []
    f = open(filepath, "r")
    sentence_started = False
    sentence_data = {"sentence": "s", "labels": []}

    for line in f.readlines():
        if line[2:6] == "text":
            sentence_started = True
            sentence_data["sentence"] = line[9:].strip()

        elif sentence_started and len(line.split("\t")) == 5:
            part1, word, label, part4, part5 = line.split("\t")
            sentence_data["labels"].append(label.strip())

        elif line[2:9] == "sent_id":
            sentence_started = False
            training_data.append(sentence_data)
            sentence_data = {"sentence": "s", "labels": []}

    f.close()
    return (training_data[1:])

def prepare_input_data(training_data):
    tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

    tokenized_inputs = tokenizer(
        [example["sentence"] for example in training_data],
        padding=True,
        truncation=True,
        return_tensors="pt",
    )

    attention_masks = tokenized_inputs["attention_mask"]

    label_mapping = {"O": 0, "B-PER": 1, "I-PER": 2, "B-LOC": 3, "I-LOC": 4, "B-ORG": 5, "I-ORG": 6, "B-MISC": 7, "I-MISC": 8}

    max_labels = max(len(example["labels"]) for example in training_data)

    label_ids = []

    for i, example in enumerate(training_data):
        example_label_ids = [label_mapping.get(label, label_mapping["O"]) for label in example["labels"]]

        example_label_ids += [label_mapping["O"]] * (max_labels - len(example_label_ids))

        label_ids.append(example_label_ids)

    labels = torch.tensor(label_ids)

    return tokenized_inputs, labels, attention_masks

filepath = "hr_set-ud-train.iob2" #changed for language
training_data = convert_IOB2_to_BERT_data(filepath)
tokenized_inputs, labels, attention_masks = prepare_input_data(training_data)

dataset = TensorDataset(tokenized_inputs["input_ids"], attention_masks, labels)
dataloader = DataLoader(dataset, batch_size=1, shuffle=True)

model_name = "bert-base-multilingual-uncased" #changed for language
model = BertForTokenClassification.from_pretrained(model_name, num_labels=9)
tokenizer = BertTokenizer.from_pretrained(model_name)
optimizer = AdamW(model.parameters(), lr=5e-5)

num_epochs = 20
num_training_steps = num_epochs * len(dataloader)
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1*num_training_steps, num_training_steps=num_training_steps)

from torch.nn.functional import pad

criterion = CrossEntropyLoss()

model.train()

total_iterations = 0

for epoch in range(2):
    for inputs, masks, labels in dataloader:
        max_length = max(inputs.size(-1) for inputs_batch in inputs)
        padded_inputs = pad(inputs, (0, max_length - inputs.size(-1)))
        padded_masks = pad(masks, (0, max_length - masks.size(-1)))
        padded_labels = pad(labels, (0, max_length - labels.size(-1)))

        outputs = model(padded_inputs, attention_mask=padded_masks, labels=padded_labels)
        loss = outputs.loss
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        scheduler.step()
        #total_iterations += 1
        #print(total_iterations)
        if (total_iterations>200):
          break

test_filepath = "hr_set-ud-test.iob2" #changed for language
training_data = convert_IOB2_to_BERT_data(filepath)

tokenized_inputs, labels, attention_masks = prepare_input_data(training_data)

batch_size = 1
test_dataset = TensorDataset(tokenized_inputs["input_ids"], attention_masks, labels)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model.to(device)
model.eval()

all_predictions = []
all_labels = []

for test_batch in test_dataloader:
    inputs, masks, labels = test_batch

    inputs = inputs.to(device)
    masks = masks.to(device)
    labels = labels.to(device)

    #forward pass
    with torch.no_grad():
        outputs = model(inputs, attention_mask=masks)

    predictions = torch.argmax(outputs.logits, dim=-1)
    all_predictions.append(predictions)
    all_labels.append(labels)

all_predictions = torch.cat(all_predictions, dim=0)
all_labels = torch.cat(all_labels, dim=0)

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import numpy as np

all_predictions = all_predictions.cpu().numpy().flatten()
all_labels = all_labels.cpu().numpy().flatten().flatten()


all_predictions = np.array(all_predictions)
all_labels = np.array(all_labels)
label_names = ["O", "B-PER", "I-PER", "B-LOC", "I-LOC", "B-ORG", "I-ORG", "B-MISC", "I-MISC"]

accuracy = accuracy_score(all_labels, all_predictions[:len(all_labels)])
conf_matrix = confusion_matrix(all_labels, all_predictions[:len(all_labels)])
report = classification_report(all_labels, all_predictions[:len(all_labels)], labels=[0,1,2,3,4,5,6], target_names=label_names)

import re

#changed for language
baseline_report = """
            precision    recall  f1-score   support

       B-ORG       0.80      0.74      0.77       414
       I-ORG       0.63      0.59      0.61       293
       B-LOC       0.91      0.90      0.91       597
       I-LOC       0.86      0.69      0.77       116
       B-PER       0.86      0.84      0.85       392
       I-PER       0.88      0.87      0.88       264

   micro avg       0.83      0.80      0.82      2076
   macro avg       0.82      0.77      0.80      2076
weighted avg       0.83      0.80      0.81      2076
"""

fine_tuned_report = report

def parse_report(report_str):
    lines = report_str.strip().split('\n')
    labels = []
    metrics = []

    for line in lines[2:-3]:
        parts = re.split(r'\s+', line.strip())
        label = parts[0]
        values = [float(x) if x != 'support' else int(parts[-1]) for x in parts[1:]]
        labels.append(label)
        metrics.append(values)

    return labels, metrics

baseline_labels, baseline_metrics = parse_report(baseline_report)
fine_tuned_labels, fine_tuned_metrics = parse_report(fine_tuned_report)

metric_diff = {}
diff_names = ["p_diff","r_diff", "f_diff", "s_diff"]
for label, baseline, fine_tuned in zip(baseline_labels, baseline_metrics, fine_tuned_metrics):
    min_len = min(len(baseline), len(fine_tuned))
    diff_values = {diff_names[i]: fine_tuned[i] - baseline[i] for i in range(min_len)}
    metric_diff[label] = diff_values

for label, diff in metric_diff.items():
    print(f"Differences for label {label}: {diff}")

print(report)