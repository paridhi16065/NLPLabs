# -*- coding: utf-8 -*-
"""TP2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IWhaBbma4Xjjd9g-QsjehG331jzMSVSC
"""

import gensim
import gensim.downloader
import nltk
import numpy
from sklearn.decomposition import PCA
from matplotlib import pyplot
import math

#for model_name in gensim.downloader.info()['models'].keys():
#  print(model_name)

###Pre-trained###
google_news_vector = gensim.downloader.load('word2vec-google-news-300')  #keyedVector dictionary of vectors with key as word

def getSentenceVector(sentence):
  words = sentence.lower().split()
  NoW = 0
  sentenceVector = numpy.zeros(300)
  for word in words:
    #print(word)
    if word in google_news_vector.index_to_key:
      sentenceVector = numpy.add(sentenceVector,google_news_vector[word])
      NoW+=1
  sentenceVector = numpy.divide(sentenceVector,NoW)
  return(sentenceVector)

sentenceFile = open("/content/T_sent.txt","r")
sentences = sentenceFile.readlines()
for i in range(len(sentences)):
  for char in '`~!@#$%^&*()-_+={}[]\\|:;\'\"<>,.?/\t\n':
    sentences[i] = sentences[i].replace(char," ")
sentenceVectors=[]
for sentence in sentences:
  sentenceVectors.append(getSentenceVector(sentence))

pca = PCA(n_components=2)

graphPts = pca.fit_transform(sentenceVectors)

#closestSentence
def cosineSimilarity(v1,v2):
  denominator = numpy.linalg.norm(v1)* numpy.linalg.norm(v2)
  if denominator != 0:
    return(numpy.dot(v1, v2)/denominator)
  else:
    return (0)

sentencePairs = []
for i in range(len(sentences)):
  maxCosSimilarity = 0
  sentencePairForTarget = sentences[i]
  for j in range(len(sentences)):
    cosSimilarityij = cosineSimilarity(sentenceVectors[i],sentenceVectors[j])
    if cosSimilarityij>maxCosSimilarity and i!=j:
      maxCosSimilarity = cosSimilarityij
      sentencePairForTarget = sentences[j]
  sentencePairs.append((sentences[i],sentencePairForTarget))


pyplot.scatter(graphPts[:,0],graphPts[:,1])
for i,sentence in enumerate(sentences):
  pyplot.annotate(sentence.split()[0], xy=(graphPts[i, 0], graphPts[i, 1]))
pyplot.rcParams['figure.figsize'] = [20, 40]
pyplot.show()

#for sp in sentencePairs:
#  print(sp)

sentence_pair_file = open("out1.2.txt",'w')
for sp in sentencePairs:
  sentence_pair_file.write(sp[0].split()[0]+"\t"+sp[1].split()[0]+"\n")
sentence_pair_file.close()

sentenceFile.close()