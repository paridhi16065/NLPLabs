# NLPLabs
NLP Labs completed for the course TALN at UniGe
Each individual lab is referred to as TP (Travaux Pratique) and I have made folders corresponding to each one

#TP1

tp1.py is a python script that does all the actions specified in the assignment. 

rawText.txt is the raw text (also available at https://www.gutenberg.org/cache/epub/71950/pg71950.txt)
T.txt is the target word file
B.txt is the basis word file

To execute the code, run on command line as

$python tp1.py rawtextfilepath basisfilepath targetfilepath

(in case the command line procedure doesn't work I have put fallback input code in comments in the file)

This code will print out the 2 plot of words and the pairings of word as (targetWord, closestTargetWord)

#TP2
Running instructions:
load_tp2.py is the script for running a pretrained model and getting the sentence embeddings. 
train_tp2.py is the script for running a word2vec model trained by me to get sentence embeddings

Run the code as usual with python (the python command on cmd) but substitute the path for T_sent file in variable sentenceFile for load_tp2.py and in variable inputSentenceFile for train_tp2.py as the path may differ on a different system

out1.2.txt is the file generated by load_tp2.py containing tab-spaced pairs of closest sentence ids for pretrained model
out2.2.txt is the file generated by train_tp2.py containing tab-spaced pairs of closest sentence ids for model trained by me

Running time:
Running time for load_tp2.py is 1min 20s seconds (with additional 5 minutes when loading the model)
Running time for train_tp2.py is 3mins

Non-default parameters:
for train_tp2.py word2vec instance, I have taken workers parameter=1 to minimise jitter (as mentioned in gensim documentation)


